{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "from math import ceil\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/codet5-vocab.json\",\n",
    "    \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/codet5-merges.txt\",\n",
    ")\n",
    "\n",
    "# Utility function to save a model using pickle\n",
    "def save_model(file_name, model):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "# Embed a sequence using the T5 model\n",
    "def embed_sequence(model, sequence):\n",
    "    out = model(\n",
    "        input_ids=torch.tensor(sequence).to(torch.int64).unsqueeze(0),\n",
    "        decoder_input_ids=torch.tensor(sequence).to(torch.int64).unsqueeze(0),\n",
    "    )\n",
    "    pooled_embedding = torch.mean(out.encoder_last_hidden_state[0], dim=0)\n",
    "    return pooled_embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_embed_sequence(model, sequence, max_tokens=512):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(sequence), max_tokens):\n",
    "        chunk = sequence[i:i+max_tokens]\n",
    "        embedding = embed_sequence(model, chunk)\n",
    "        embeddings.append(embedding)\n",
    "    # Aggregate embeddings for all chunks (e.g., average or sum)\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_class_in_batches(df, model, df_path, batch_size=100):\n",
    "    if 'embeded_sequence' not in df.columns:\n",
    "        df['embeded_sequence'] = None\n",
    "\n",
    "    total_batches = ceil(len(df) / batch_size)\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(df))\n",
    "        print(f\"Processing batch {batch_idx + 1}/{total_batches} (rows {start_idx} to {end_idx})\")\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            row = df.iloc[i]\n",
    "            print(f\"Row {i}: Sample ID = {row['sample_id']}\")\n",
    "            try:\n",
    "                # Compute the embedding\n",
    "                embedding = embed_sequence(model, tokenizer.encode(row['method']).ids)\n",
    "                df.at[i, 'embeded_sequence'] = embedding\n",
    "            except Exception as e:\n",
    "                print(f\"EXCEPTION at row {i}\")\n",
    "                print(e)\n",
    "\n",
    "        # Save progress after each batch\n",
    "        pd.to_pickle(df, df_path)\n",
    "        print(f\"Batch {batch_idx + 1} saved to {df_path}\")\n",
    "\n",
    "    print(\"All batches processed and saved.\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_line_by_line_in_batches(df, model, df_path, batch_size=100):\n",
    "    directory = os.path.dirname(df_path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    df = df.copy()\n",
    "    df['embeded_sequence_sum'] = None\n",
    "    df['embeded_sequence_avg'] = None\n",
    "\n",
    "    total_rows = len(df)\n",
    "    for start in range(0, total_rows, batch_size):\n",
    "        end = min(start + batch_size, total_rows)\n",
    "        df_batch = df.iloc[start:end]\n",
    "        print(f\"Processing batch {start} to {end} (total {total_rows})\")\n",
    "        for i, row in df_batch.iterrows():\n",
    "            print(f\"Processing row {i}: Sample ID {row['sample_id']}\")\n",
    "            lines = row['method'].split('\\n')\n",
    "            embeded = []\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    if len(line) > 0:\n",
    "                        tokens = tokenizer.encode(line).ids\n",
    "                        embeded.append(embed_sequence(model, tokens))\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception in line processing: {e}\\nLine: {line}\")\n",
    "            if embeded:\n",
    "                df.at[i, 'embeded_sequence_sum'] = pd.Series(np.sum(np.asarray(embeded), axis=0).tolist())\n",
    "                df.at[i, 'embeded_sequence_avg'] = pd.Series(np.mean(np.asarray(embeded), axis=0).tolist())\n",
    "\n",
    "        pd.to_pickle(df, df_path)\n",
    "        print(f\"Batch {start}-{end} saved to {df_path}\")\n",
    "\n",
    "    print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/Users/mac/Desktop/Code_Smell_Detection/dataset/data_class/data_class.csv')\n",
    "df['label'] = np.where(df.severity == 'none', 0, 1)\n",
    "\n",
    "# Process with small model\n",
    "small_config_path = \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/small/config.json\"\n",
    "small_model_path = \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/small/pytorch_model.bin\"\n",
    "\n",
    "small_config = T5Config.from_json_file(small_config_path)\n",
    "model_small = T5ForConditionalGeneration(small_config)\n",
    "model_small.load_state_dict(torch.load(small_model_path, map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed line-by-line for the subset\n",
    "embed_line_by_line_in_batches(\n",
    "    df,\n",
    "    model_small,\n",
    "    '/Users/mac/Desktop/Code_Smell_Detection/dataset/data_class/T5/df_dc_embeded_by_line_small.pkl',\n",
    "     batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed class-level embedding for the subset\n",
    "embed_class_in_batches(\n",
    "    df,\n",
    "    model_small,\n",
    "    '/Users/mac/Desktop/Code_Smell_Detection/dataset/data_class/T5/df_dc_embeded_small.pkl',\n",
    "    batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean up the small model\n",
    "del model_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process with base model\n",
    "base_config_path = \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/base/config.json\"\n",
    "base_model_path = \"/Users/mac/Desktop/Code_Smell_Detection/dataset/codeT5/base/pytorch_model.bin\"\n",
    "\n",
    "base_config = T5Config.from_json_file(base_config_path)\n",
    "model_base = T5ForConditionalGeneration(base_config)\n",
    "model_base.load_state_dict(torch.load(base_model_path, map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed line-by-line for the subset\n",
    "embed_class_in_batches(\n",
    "    df,\n",
    "    model_base,\n",
    "    '/Users/mac/Desktop/Code_Smell_Detection/dataset/data_class/T5/df_dc_embeded_by_line_base.pkl',\n",
    "    batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed class-level embedding for the subset\n",
    "embed_class_in_batches(\n",
    "    df,\n",
    "    model_base,\n",
    "    '/Users/mac/Desktop/Code_Smell_Detection/dataset/data_class/T5/df_dc_embeded_base.pkl',\n",
    "    batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the base model\n",
    "del model_base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
