{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PLBART tokenizer and model\n",
    "model_name = \"uclanlp/plbart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/kaggle/input/data-class-code-smells/data_class.csv')\n",
    "df['label'] = np.where(df.severity == 'none', 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_line_by_line_in_batches(df, df_path, batch_size=100):\n",
    "    directory = os.path.dirname(df_path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['embeded_sequence_sum'] = None\n",
    "    df['embeded_sequence_avg'] = None\n",
    "\n",
    "    total_rows = len(df)\n",
    "    for start in range(0, total_rows, batch_size):\n",
    "        end = min(start + batch_size, total_rows)\n",
    "        df_batch = df.iloc[start:end]\n",
    "        print(f\"Processing batch {start} to {end} (total {total_rows})\")\n",
    "        \n",
    "        for i, row in df_batch.iterrows():\n",
    "            print(f\"Processing row {i}: Sample ID {row['sample_id']}\")\n",
    "            lines = row['method'].split('\\n')\n",
    "            embeded = []\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    if len(line.strip()) > 0:  # Only process non-empty lines\n",
    "                        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(**inputs)\n",
    "                        embeddings = outputs.last_hidden_state[:, 0, :]  # Extract the CLS token embedding\n",
    "                        embeded.append(embeddings.cpu().numpy())  # Convert embeddings to numpy\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception in line processing: {e}\\nLine: {line}\")\n",
    "            \n",
    "            if embeded:\n",
    "                df.at[i, 'embeded_sequence_sum'] = np.sum(np.asarray(embeded), axis=0).tolist()\n",
    "                df.at[i, 'embeded_sequence_avg'] = np.mean(np.asarray(embeded), axis=0).tolist()\n",
    "\n",
    "        # Save the DataFrame after processing each batch\n",
    "        pd.to_pickle(df, df_path)\n",
    "        print(f\"Batch {start}-{end} saved to {df_path}\")\n",
    "\n",
    "    print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed line-by-line for the subset\n",
    "embed_line_by_line_in_batches(\n",
    "    df,\n",
    "    '/kaggle/working/df_dc_embeded_by_line_plbart.pkl',\n",
    "    batch_size=50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
